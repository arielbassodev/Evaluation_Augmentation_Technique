{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from   torchvision.models import resnet50\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize((255, 255)),\n",
    "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "train_set = datasets.ImageFolder(root='C:\\\\Users\\\\abassoma\\\\Documents\\\\Dataset\\\\Indonesian_dataset\\\\indonesian_train_dataset',transform=transform)\n",
    "val_set = datasets.ImageFolder(root='C:\\\\Users\\\\abassoma\\\\Documents\\\\Dataset\\\\Indonesian_dataset\\\\indonesian_test_dataset',transform=transform)\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(val_set,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    img = np.array(img)\n",
    "    img = img.transpose(1,2,0)\n",
    "    plt.imshow(img)\n",
    "\n",
    "x = next(iter((train_loader)))[0][2]\n",
    "showImage(x)\n",
    "\n",
    "t5= transforms.RandomAffine(\n",
    "    degrees=0,  \n",
    "    translate=(0.5, 0))\n",
    "x4= t5(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training resnet50 with all the 8*26 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = resnet50(pretrained=True).to('cuda')\n",
    "num_feature = model2.fc.in_features\n",
    "model2.fc = nn.Linear(num_feature,26)\n",
    "\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model2.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Module(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = model2\n",
    "        # Définir la loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        num_classes = 26\n",
    "        # Définir les métriques\n",
    "        self.train_acc = TM.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.train_top3 = TM.Accuracy(task='multiclass', num_classes=num_classes, top_k=3)\n",
    "        \n",
    "        self.val_acc = TM.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.val_top3 = TM.Accuracy(task='multiclass', num_classes=num_classes, top_k=3)\n",
    "        self.val_recall = TM.Recall(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        logits = self.model(images)\n",
    "        loss = self.criterion(logits, targets)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        self.train_acc(preds, targets)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('train_acc', self.train_acc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        logits = self.model(images)\n",
    "        loss = self.criterion(logits, targets)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        self.val_acc(preds, targets)\n",
    "        self.val_recall(preds, targets)  \n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('val_acc', self.val_acc, on_step=True, on_epoch=True)\n",
    "        self.log('val_recall', self.val_recall, on_step=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Optimiser uniquement les paramètres du classifieur (la dernière couche)\n",
    "        return optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_module = Module()\n",
    "# trainer = L.Trainer(max_epochs=45)\n",
    "# trainer.fit(\n",
    "#     my_module,\n",
    "#     train_loader,\n",
    "#     test_loader\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use 8**26 observations to Train the SIMCLR Algorithm and use 5*26 for the fine tuning on the classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.Resize((255, 255))  \n",
    "])\n",
    "\n",
    "train_set = datasets.ImageFolder(root='C:\\\\Users\\\\abassoma\\\\Documents\\\\Dataset\\\\Indonesian_dataset\\\\indonesian_train_1',transform=transform)\n",
    "val_set = datasets.ImageFolder(root='C:\\\\Users\\\\abassoma\\\\Documents\\\\Dataset\\\\Indonesian_dataset\\\\indonesian_train_2',transform=transform)\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(val_set,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model perfomence with several transformations one by one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "transformation_groups = {\n",
    "    \"translations\": [\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0)),  # Translation de 10%\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.2, 0)),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.3, 0)),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.4, 0)),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.5, 0)),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.6, 0)),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.7, 0)),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.8, 0))   \n",
    "    ],\n",
    "    \"rotations\": [\n",
    "        transforms.RandomAffine(degrees=10, translate=(0, 0)),  # Rotation de 10°\n",
    "        transforms.RandomAffine(degrees=20, translate=(0, 0)),  \n",
    "        transforms.RandomAffine(degrees=30, translate=(0, 0)),  \n",
    "        transforms.RandomAffine(degrees=40, translate=(0, 0)),  \n",
    "        transforms.RandomAffine(degrees=50, translate=(0, 0)),  \n",
    "        transforms.RandomAffine(degrees=60, translate=(0, 0)),  \n",
    "        transforms.RandomAffine(degrees=70, translate=(0, 0)),  \n",
    "        transforms.RandomAffine(degrees=80, translate=(0, 0))   \n",
    "    ],\n",
    "    \"ResizedCrop\": [\n",
    "        transforms.RandomResizedCrop(size=128, scale=(0.8, 1.0)),  # Découpe aléatoire redimensionnée\n",
    "        transforms.RandomResizedCrop(size=64, scale=(0.5, 1.0)),   \n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.5, 1.0)),  \n",
    "        transforms.RandomResizedCrop(size=128, scale=(0.6, 0.9)),  \n",
    "        transforms.RandomResizedCrop(size=128, scale=(0.7, 1.0)),  \n",
    "        transforms.RandomResizedCrop(size=128, scale=(0.3, 0.7)),  \n",
    "        transforms.RandomResizedCrop(size=192, scale=(0.5, 1.0)),  \n",
    "        transforms.RandomResizedCrop(size=32, scale=(0.5, 1.0))    \n",
    "    ],\n",
    "    \"ColorJitter\": [\n",
    "        transforms.ColorJitter(brightness=0.5),  # Variation de luminosité\n",
    "        transforms.ColorJitter(contrast=0.5),   \n",
    "        transforms.ColorJitter(saturation=0.5),  \n",
    "        transforms.ColorJitter(hue=0.3),        \n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),  \n",
    "        transforms.ColorJitter(saturation=0.3, hue=0.1),        \n",
    "        transforms.ColorJitter(brightness=0.4, saturation=0.4), \n",
    "        transforms.ColorJitter(contrast=0.4, hue=0.2)           \n",
    "    ],\n",
    "    \"GaussianBlur\": [\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),  # Flou gaussien\n",
    "        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2)),  \n",
    "        transforms.GaussianBlur(kernel_size=(7, 7), sigma=(0.1, 3)),  \n",
    "        transforms.GaussianBlur(kernel_size=(9, 9), sigma=(0.1, 4)),  \n",
    "        transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.5, 1)),  \n",
    "        transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.2, 0.8)),  \n",
    "        transforms.GaussianBlur(kernel_size=(3, 5), sigma=(0.2, 1)),  \n",
    "        transforms.GaussianBlur(kernel_size=(7, 5), sigma=(0.3, 2))   \n",
    "    ],\n",
    "    \"RandomErasing\": [\n",
    "        transforms.RandomErasing(p=0.3, scale=(0.02, 0.33), ratio=(0.3, 3.3)),  # Effacement aléatoire\n",
    "        transforms.RandomErasing(p=0.4, scale=(0.1, 0.2), ratio=(0.3, 3.3)),   \n",
    "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.3), ratio=(0.3, 3.3)),   \n",
    "        transforms.RandomErasing(p=0.2, scale=(0.01, 0.2), ratio=(0.5, 1.5)),  \n",
    "        transforms.RandomErasing(p=0.3, scale=(0.05, 0.25), ratio=(0.4, 2.5)),  \n",
    "        transforms.RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.2, 1.5)),   \n",
    "        transforms.RandomErasing(p=0.4, scale=(0.03, 0.3), ratio=(0.4, 1.5)),   \n",
    "        transforms.RandomErasing(p=0.3, scale=(0.01, 0.15), ratio=(0.2, 1.0))   \n",
    "    ],\n",
    "    \"RandomHorizontalFlip\": [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Inversion horizontale\n",
    "        transforms.RandomHorizontalFlip(p=0.7),  \n",
    "        transforms.RandomHorizontalFlip(p=0.3),  \n",
    "        transforms.RandomHorizontalFlip(p=0.9),  \n",
    "        transforms.RandomHorizontalFlip(p=0.2),\n",
    "        transforms.RandomHorizontalFlip(p=0.6),  \n",
    "        transforms.RandomHorizontalFlip(p=0.4),  \n",
    "        transforms.RandomHorizontalFlip(p=0.8)   \n",
    "    ],\n",
    "    \"RandomVerticalFlip\": [\n",
    "        transforms.RandomVerticalFlip(p=0.5),    # Inversion verticale\n",
    "        transforms.RandomVerticalFlip(p=0.7),    \n",
    "        transforms.RandomVerticalFlip(p=0.3),    \n",
    "        transforms.RandomVerticalFlip(p=0.9),   \n",
    "        transforms.RandomVerticalFlip(p=0.2),    \n",
    "        transforms.RandomVerticalFlip(p=0.6),    \n",
    "        transforms.RandomVerticalFlip(p=0.4),    \n",
    "        transforms.RandomVerticalFlip(p=0.8)      \n",
    "    ],\n",
    "    \"others\": [\n",
    "        transforms.RandomRotation(degrees=30),    # Rotation aléatoire\n",
    "        transforms.RandomHorizontalFlip(p=0.7),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  \n",
    "        transforms.ColorJitter(brightness=0.2),  \n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0)),  \n",
    "        transforms.RandomGrayscale(p=0.2),       \n",
    "        transforms.RandomAffine(degrees=10),     \n",
    "        transforms.RandomAffine(degrees=20)       \n",
    "    ],\n",
    "    \"Bad_Mixed\" : [\n",
    "        transforms.RandomRotation(degrees=90), \n",
    "        transforms.RandomErasing(p=0.4, scale=(0.1, 0.2), ratio=(0.3, 3.3)),\n",
    "        transforms.RandomGrayscale(p=0.2),  \n",
    "        transforms.GaussianBlur(kernel_size=(9, 9), sigma=(0.1, 4)),  \n",
    "        transforms.RandomAffine(degrees=40, translate=(0, 0)),\n",
    "        transforms.ColorJitter(brightness=0.2),     \n",
    "        transforms.ColorJitter(brightness=0.2),  \n",
    "        transforms.GaussianBlur(kernel_size=(9, 9), sigma=(0.1, 4)),  \n",
    "    ]\n",
    "}\n",
    "\n",
    "# Sélectionner les groupes de transformations à utiliser\n",
    "def get_transformations(active_groups):\n",
    "    selected_transformations = []\n",
    "    for group in active_groups:\n",
    "        selected_transformations.extend(transformation_groups[group])\n",
    "    return selected_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 255, 255])\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour choisir une transformation aléatoire parmi les groupes sélectionnés\n",
    "def random_choose(transformation_list):\n",
    "    p = random.randint(0, len(transformation_list) - 1)\n",
    "    return transformation_list[p]\n",
    "\n",
    "# Générer deux batchs d'images transformées en fonction des transformations actives\n",
    "def generate_batch(batch_image, active_groups):\n",
    "    selected_transformations = get_transformations(active_groups)\n",
    "    first_batch = []\n",
    "    second_batch = []\n",
    "    \n",
    "    for im in batch_image:\n",
    "        transform_batch_1 = random_choose(selected_transformations)\n",
    "        transform_batch_2 = random_choose(selected_transformations)\n",
    "        x = transform_batch_1(im)\n",
    "        y = transform_batch_2(im)\n",
    "        first_batch.append(x)\n",
    "        second_batch.append(y)\n",
    "    \n",
    "    # Convertir les listes en tenseurs en empilant directement\n",
    "    first_batch_tensor = torch.stack(first_batch)\n",
    "    second_batch_tensor = torch.stack(second_batch)\n",
    "    \n",
    "    return first_batch_tensor, second_batch_tensor\n",
    "\n",
    "test = next(iter(train_loader))[0]\n",
    "print(test.shape)\n",
    "batch_1, batch_2  =  generate_batch(test, active_groups=['Bad_Mixed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 255, 255])\n"
     ]
    }
   ],
   "source": [
    "print(batch_1[0].shape)\n",
    "from lightly.loss import NTXentLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = [[2,3,4],[4,2,5]]\n",
    "a = np.array(a)\n",
    "print(a.shape)\n",
    "a = torch.from_numpy(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = resnet50(pretrained=True).to('cuda')\n",
    "\n",
    "class HeadProjection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(1000, 200)\n",
    "        self.fc2 = nn.Linear(200,29)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "Projection = HeadProjection().to('cuda')\n",
    "\n",
    "class SIMCLR(nn.Module):\n",
    "    def __init__(self,backbone,projection):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection = Projection\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.projection(self.backbone(x))\n",
    "        return x\n",
    "simclr_model = SIMCLR(backbone,Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pytorch_metric_learning import losses\n",
    "import torch.optim as optim\n",
    "criterion = NTXentLoss()\n",
    "optimizer = optim.SGD(simclr_model.parameters(), lr=0.001)\n",
    "\n",
    "def training(train_loader, test_loader, num_epochs, active_groups):\n",
    "    epoch_losses = [] \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        print(f\"Début de l'époque {epoch + 1}\")\n",
    "        \n",
    "        for step, (data, label) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Générer les deux batchs avec les groupes de transformations activés\n",
    "            batch_1, batch_2 = generate_batch(data, active_groups)\n",
    "            batch_1, batch_2 = batch_1.to('cuda'), batch_2.to('cuda')\n",
    "            \n",
    "            embedding_batch_1 = simclr_model(batch_1)\n",
    "            embedding_batch_2 = simclr_model(batch_2)\n",
    "            loss = criterion(embedding_batch_1,embedding_batch_2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "    \n",
    "    # Plot des erreurs d'entraînement\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), epoch_losses, marker='o', label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig('Training_loss_simclr_others_essai_4.png')\n",
    "    plt.show()\n",
    "\n",
    "# Exemple d'appel de la fonction avec les groupes actifs\n",
    "training(train_loader, test_loader, 70, active_groups=[\"ColorJitter\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune the model and just train the classification head with 3**26 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netwk = simclr_model.backbone\n",
    "num_ftrs = netwk.fc.in_features \n",
    "print(num_ftrs)\n",
    "netwk.fc = nn.Linear(num_ftrs,26)\n",
    "\n",
    "# Geler toutes les couches du modèle SimCLR pré-entraîné\n",
    "for param in netwk.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Débloquer uniquement la dernière couche fully connected (fc)\n",
    "for param in netwk.fc.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize((224, 224)),\n",
    "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "train_set = datasets.ImageFolder(root='C:\\\\Users\\\\abassoma\\\\Documents\\\\Dataset\\\\Indonesian_dataset\\\\indonesian_train_2',transform=transform)\n",
    "val_set = datasets.ImageFolder(root='C:\\\\Users\\\\abassoma\\\\Documents\\\\Dataset\\\\Indonesian_dataset\\\\indonesian_test_dataset',transform=transform)\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(val_set,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Module(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = netwk\n",
    "        # Définir la loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        num_classes = 26\n",
    "        # Définir les métriques\n",
    "        self.train_acc = TM.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.train_top3 = TM.Accuracy(task='multiclass', num_classes=num_classes, top_k=3)\n",
    "        \n",
    "        self.val_acc = TM.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.val_top3 = TM.Accuracy(task='multiclass', num_classes=num_classes, top_k=3)\n",
    "        self.val_recall = TM.Recall(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        logits = self.model(images)\n",
    "        loss = self.criterion(logits, targets)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        self.train_acc(preds, targets)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('train_acc', self.train_acc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        logits = self.model(images)\n",
    "        loss = self.criterion(logits, targets)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        self.val_acc(preds, targets)\n",
    "        self.val_recall(preds, targets)  \n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('val_acc', self.val_acc, on_step=True, on_epoch=True)\n",
    "        self.log('val_recall', self.val_recall, on_step=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        return optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module = Module()\n",
    "trainer = L.Trainer(max_epochs=50)\n",
    "trainer.fit(\n",
    "    my_module,\n",
    "    train_loader, \n",
    "    test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
